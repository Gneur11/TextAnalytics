{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "names = [\"condensed_2010.json\",\"condensed_2011.json\",\"condensed_2012.json\",\"condensed_2013.json\",\n",
    "         \"condensed_2014.json\", \"condensed_2015.json\",\"condensed_2016.json\",\"condensed_2017.json\",\"condensed_2018.json\",\n",
    "         \"trump2019_26_03.json\"]\n",
    "\n",
    "data = pd.read_json(\"condensed_2009.json\")\n",
    "for element in names:\n",
    "    data1 = pd.read_json(element)\n",
    "    print(len(data1),element)\n",
    "    data = data.append(data1,sort=True)\n",
    "data = data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pd.to_datetime(stamps, format=\"%Y-%m-%d %H:%M:%S\").sort_values()\n",
    "\n",
    "data['created_at'] = pd.to_datetime(data.created_at, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "data.sort_values(by=['created_at'], inplace=True, ascending=True)\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "data.to_json(\"orderedTwitterArchive.json\")\n",
    "data.to_csv(\"orderedTwitterArchive.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"orderedTwitterArchive.json\")\n",
    "data['created_at'] = pd.to_datetime(data.created_at, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "data.sort_values(by=['created_at'], inplace=True, ascending=True)\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (25, 10))\n",
    "ax = sns.lineplot(x=data.index, y=\"favorite_count\", data=data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (25, 10))\n",
    "ax = sns.lineplot(x=data.index, y=\"retweet_count\", data=data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"][2005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# idee\n",
    "\n",
    "NLP:\n",
    "    - pos tagging per contare numero di aggettivi \n",
    "    - qualcosa per vedere se aggettivi sono positivi o negativi (direttamente sentiment analysis)?\n",
    "    - rimuovere gli @ vs tenere solo i pi√π frequenti \n",
    "    - rimuovere i link\n",
    "    - pulire gli hashtag? \n",
    "    - word2vec distance per avere simili tweet assieme nello spazio vettoriale?\n",
    "    - ridurre parole presenti? \n",
    "    - tfidf?\n",
    "    \n",
    "Processo:\n",
    "    - clustering interno all'anno\n",
    "    - clustering generale \n",
    "    - clustering con/senza sentiment meaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
